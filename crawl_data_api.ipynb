{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c1919610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c873ee",
   "metadata": {},
   "source": [
    "# I. Lấy thông tin chung\n",
    "- Lấy thông tin của tất cả các quán ăn thuộc 1 tỉnh/TP. Rộng hơn là thông tin tất cả quán ăn của nhiều tỉnh thành\n",
    "- Với mỗi quán ăn, lấy những trường thông tin cơ bản như\n",
    "    + name, addr, CityId, RestaurantId, RestaurantStatus <font color=green>// thông tin cơ bản</font>\n",
    "    + AvgRating\n",
    "    + TotalPictures, TotalSaves, TotalReviews, TotalFavourites, TotalViews, TotalCheckIns\n",
    "    + CreatedOn <font color=green>//ngày shop dc tạo đầu tiên trên foody (trường này bị sao rồi, toàn mặc định)</font>\n",
    "    + Latitude & Longitude <font color=green>//toạ độ</font>\n",
    "    + ResUrlReviews <font color=green>//URL dẫn tới trang chứa bình luận của shop đó</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc232c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_page(page, st, dist):\n",
    "    '''extract 1 page'''\n",
    "    url = f'https://www.foody.vn/ho-chi-minh/dia-diem?vt=row&st={st}&dt={dist}&page={page}'\n",
    "    all_shops_API = requests.get(url, headers={'X-Requested-With': 'XMLHttpRequest',\n",
    "                                               'Cookie': 'FOODY.AUTH=A3F33DD0BA0DC443960AC294DA1D898EE203A64E31B64523D3674F29D60EF3C3C900F1F3BF70DAC47FD0ED268F012BD8FD06CCA143E3FCC2F79AA22CFF031D91A06F5D97B96B09529CF8E5A06E58BCF34312AFDA1F37E6B39CC56A6BA525D72DEDDF1EFE136334F777A1AD191BC3B393CA5D7B3008AA54A9565C21793E196AB15D19E8867327553F696DDCA2938C22208B84620BAA2F757C9D4B8E2FF3CE8A28E6EBC891AAE2F227C02CF6834427BD815163F0DAB98F2E47CECEA44EE3CB88F9A94D33123EEA15B660CF6DE09385DF9EAFD8741C8B4936BF4B5C40B003150E622D303BAC626EBF7FD60BCB19647A46FC'})\n",
    "    data = all_shops_API.text\n",
    "\n",
    "    # handle errors\n",
    "    try:\n",
    "        json_data = json.loads(data)\n",
    "        search_items = json_data['searchItems']\n",
    "    except: # no data\n",
    "        return []\n",
    "    \n",
    "    # get basic shop's info\n",
    "    shop_attribs = []\n",
    "    \n",
    "    for shop in search_items: \n",
    "        shop_attribs.append({'ReviewUrl' : shop['ReviewUrl'],\n",
    "                             'name': shop['Name'],\n",
    "                             'Address': shop['Address'],\n",
    "                             'districtid': shop['DistrictId'],\n",
    "                             'RestaurantId': shop['Id'],\n",
    "                             'RestaurantStatus': shop['Status'],\n",
    "                             'avgrating' : shop['AvgRatingOriginal'],\n",
    "                             'TotalPictures' : shop['TotalPictures'],\n",
    "                             'TotalSaves' : shop['TotalSaves'],\n",
    "                             'TotalReviews' : shop['TotalReview'],\n",
    "                             'TotalFavourites' : shop['TotalFavourite'],\n",
    "                             'TotalViews' : shop['TotalView'],\n",
    "                             'TotalCheckIns' : shop['TotalCheckins'],\n",
    "                             'Latitude'  : shop['Latitude'],\n",
    "                             'Longitude'  : shop['Longitude']})\n",
    "    \n",
    "    return shop_attribs # [{},{},..]\n",
    "\n",
    "def get_single_district(dist=1):\n",
    "    '''get all shops in a single district'''\n",
    "    page = 1\n",
    "    all_shop = []\n",
    "    empty = False\n",
    "\n",
    "    for page in range(1, 101):\n",
    "        if empty:\n",
    "            break\n",
    "        for st in range(1, 60):\n",
    "            time.sleep(1)\n",
    "            one_page = get_single_page(page, st, dist) \n",
    "            \n",
    "            if not one_page: # check empty\n",
    "                empty = True\n",
    "                break\n",
    "            all_shop.extend(one_page)\n",
    "    return all_shop # [{},{},..]                       \n",
    "\n",
    "def save_district_to_file(dist):\n",
    "    shops_in_a_district = get_single_district(dist)\n",
    "    df = pd.DataFrame.from_dict(shops_in_a_district) \n",
    "    df.dropna(subset='ReviewUrl').drop_duplicates().to_csv(f'q_id_{dist}.csv', index = False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a01784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save district_id = 12 successfully\n",
      "save district_id = 13 successfully\n",
      "save district_id = 14 successfully\n"
     ]
    }
   ],
   "source": [
    "all_dist = '1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19,2,18,693,696,699,695,694,698'.split(',')\n",
    "for dist in all_dist:\n",
    "    save_district_to_file(dist)\n",
    "    print(f'save district_id = {dist} successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38055120",
   "metadata": {},
   "source": [
    "## Merge data của tất cả các quận"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212993c6",
   "metadata": {},
   "source": [
    "- Merge các file quận/huyện độc lập thành 1 dataframe duy nhất `df_all` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38ef61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "col_order = list(pd.read_csv('crawled_all_shops/q1.csv'))\n",
    "for file in os.listdir('crawled_all_shops/'):\n",
    "    df_dist = pd.read_csv(f\"crawled_all_shops/{file}\")\n",
    "    df_dist.reindex(col_order, axis=1) # df_dist's col order must be unified\n",
    "    df_all = pd.concat([df_all, df_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ed98e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58365, 15)\n",
      "drop_dup(ReviewUrl) + drop_na(ReviewUrl): (58365, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape)\n",
    "print(\"drop_dup(ReviewUrl) + drop_na(ReviewUrl):\", df_all.drop_duplicates('ReviewUrl').dropna(subset='ReviewUrl').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c8e5bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_all = df_all.drop_duplicates('ReviewUrl').dropna(subset='ReviewUrl')\n",
    "df_all.rename(columns={'name': 'Name', 'avgrating': 'AvgRating', 'districtid': 'District'}, inplace=True)\n",
    "df_all.to_csv(f'crawled_all_shops/all_dist.csv', index = False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f545ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đổi df['District'] từ mã encode quận sang quận bằng chữ\n",
    "all_dist_encode = '1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19,2,18,693,696,699,695,694,698'.split(',')\n",
    "all_dist = '1,2,3,4,5,6,7,8,9,10,11,12,Bình Thạnh,Tân Bình,Phú Nhuận,Tân Phú,Gò Vấp,Bình Tân,Tp. Thủ Đức,Huyện Bình Chánh,Huyện Nhà Bè,Huyện Hóc Môn,Huyện Củ Chi,Huyện Cần Giờ'.split(',')\n",
    "df_all['District'] = df_all['District'].apply(lambda x: all_dist[all_dist_encode.index(str(int(x)))] if x == x else \"\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39721e43",
   "metadata": {},
   "source": [
    "- Merge chung với file Data_TPHCM đang chứa 69k+ dòng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "23595e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đọc Data_TPHCM & bsung các gtrị rỗng vào các empty_cols\n",
    "data_hcm = pd.read_csv('crawled_all_shops/Data_TPHCM.csv')[:-1] # drop 'city' col\n",
    "empty_cols = list(set(list(df_all)).difference(set(list(data_hcm))))\n",
    "data_hcm[empty_cols] = np.nan \n",
    "data_hcm = data_hcm.reindex(list(df_all), axis=1)\n",
    "# data_hcm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3e12f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess \n",
    "data_hcm['District'] = data_hcm['District'].apply(lambda x: x[2:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2457b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93669, 15)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge data\n",
    "data_hcm = pd.concat([data_hcm, df_all])\n",
    "data_hcm = data_hcm.drop_duplicates('ReviewUrl').dropna(subset='ReviewUrl')\n",
    "data_hcm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "25cf69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged data to csv\n",
    "data_hcm.to_csv(f'crawled_all_shops/data_hcm.csv', index = False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911a9b4",
   "metadata": {},
   "source": [
    "# II. Lấy thông tin cụ thể từng quán ăn\n",
    "Thông tin lần này chia thành 2 loại:\n",
    "- Thông tin thực đơn (Get delivery dishes)\n",
    "    - dish_type_name <font color=green>//Loại đồ ăn: 1 loại đồ ăn gồm nhiều món ăn, VD: bún thì có bún cá, bún chả</font>\n",
    "    - total_like <font color=green>//tổng lượt like loại đồ ăn đó</font>\n",
    "    - is_available <font color=green>//loại đồ ăn đó còn món ko</font>\n",
    "    - dish_name <font color=green>//món ăn thuộc loại đồ ăn đó. VD: bún cá thập cẩm</font>\n",
    "    - dish_price <font color=green>//giá 1 món ăn thuộc 1 loại đồ ăn </font>\n",
    "    - options: <font color=green>// có option nào cho món ăn đó. VD: có option chọn thêm topping như rau, cua,... </font>\n",
    "        [\n",
    "        option_1: name, price;\n",
    "        option_2: name, price;\n",
    "        ....\n",
    "        ]\n",
    "    - option_min_select, option_max_select\n",
    "\n",
    "- Thông tin chi tiết quán ăn (Get detail):\n",
    "    - phone \n",
    "\t- district_id\n",
    "\t- category <font color=green>//loại hình quán ăn?</font>\n",
    "\t- cuisines <font color=green>//quán ăn thuộc phân khúc món nào? món Việt, Âu,...?</font>\n",
    "\t- service_fee <font color=green>//fí dịch vụ</font>\n",
    "\t- avg_price <font color=green>// chắc là giá trung bình của quán ăn.</font>\n",
    "\t- min_order_value <font color=green>//fải mua tối thiểu bnhiêu tiền?</font>\n",
    "\t- promotion <font color=green>// trong này nhiều trường nhỏ, tự nghiên cứu thêm</font>\n",
    "\t- min_charge <font color=green>//fí fụ thu nhỏ nhất</font>\n",
    "\t- week_days, operating <font color=green>//thời gian mở cửa</font>\n",
    "\t- min_shipping_fee <font color=green>// có thể là giá ship thấp nhất</font>\n",
    "\t- is_foody_delivery <font color=green>// có thể là shop này có phải là shop bán mang về hay không</font>\n",
    "\t- price_range <font color=green>// khoảng giá min – max của quán.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe47d9",
   "metadata": {},
   "source": [
    "- Lấy **menu** của 1 quán ăn: xây dựng hàm nhận vào `id_quán_ăn` & get về thông tin menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f69116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "menu_df = pd.DataFrame(columns=['dish_type_id', 'dish_type_name'])\n",
    "menu_dish_df = pd.DataFrame(columns=['dish_type_id', 'dish_id', 'dish_name', 'dish_description', 'dish_price_value', 'dish_total_like', 'dish_is_available'])\n",
    "menu_dish_option_df = pd.DataFrame(columns=['dish_type_id', 'dish_id', 'option_id', 'option_min_select', 'option_max_select'])\n",
    "menu_dish_option_item_df = pd.DataFrame(columns=['dish_type_id', 'dish_id', 'option_id', 'item_id', 'item_name', 'item_price'])\n",
    "\n",
    "def get_delivery_dish(restaurant_id):\n",
    "\tglobal menu_df, menu_dish_df, menu_dish_option_df, menu_dish_option_item_df\n",
    "\tdelivery_dish_API = requests.get(f\"https://gappapi.deliverynow.vn/api/dish/get_delivery_dishes?request_id={restaurant_id}&id_type=1\", \n",
    "\t\t\t\t\t\t\t\t\t headers={'x-foody-api-version': '1',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'x-foody-app-type': '1004',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'x-foody-client-language': 'vi',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'x-foody-client-type': '1',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'x-foody-client-version': '1',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'X-Foody-Client-Id': 'cookies.__ondemand_sessionid'\n",
    "\t\t\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "\tdata = delivery_dish_API.text\n",
    "\ttry:\n",
    "\t\tdataJson = json.loads(data)\n",
    "\t\tmenu_infos = dataJson['reply']['menu_infos']\n",
    "\texcept:\n",
    "\t\treturn\n",
    "\n",
    "\tmenu_df_temp = pd.DataFrame(columns=['restaurant_id', 'dish_type_id', 'dish_type_name'])\n",
    "\tmenu_dish_df_temp = pd.DataFrame(columns=['restaurant_id', 'dish_type_id', 'dish_id', 'dish_name', 'dish_description', 'dish_price_value', 'dish_total_like', 'dish_is_available'])\n",
    "\tmenu_dish_option_df_temp = pd.DataFrame(columns=['restaurant_id', 'dish_type_id', 'dish_id', 'option_id', 'option_min_select', 'option_max_select'])\n",
    "\tmenu_dish_option_item_df_temp = pd.DataFrame(columns=['restaurant_id', 'dish_type_id', 'dish_id', 'option_id', 'item_id', 'item_name', 'item_price'])\n",
    "\n",
    "\tfor menu_info in menu_infos:\n",
    "\t\tmenu_df_temp.loc[len(menu_df_temp.index)] = [restaurant_id, menu_info['dish_type_id'], menu_info['dish_type_name']]\n",
    "\t\tfor dish in menu_info['dishes']:\n",
    "\t\t\tmenu_dish_df_temp.loc[len(menu_dish_df_temp.index)] = [\n",
    "\t\t\t\t\trestaurant_id,\n",
    "\t\t\t\t\tmenu_info['dish_type_id'],\n",
    "\t\t\t\t\tdish['id'],\n",
    "\t\t\t\t\tdish['name'],\n",
    "\t\t\t\t\tdish['description'],\n",
    "\t\t\t\t\tdish['price']['value'],\n",
    "\t\t\t\t\tdish['total_like'],\n",
    "\t\t\t\t\tdish['is_available']\n",
    "\t\t\t]\n",
    "\t\t\tfor option in dish['options']:\n",
    "\t\t\t\tmenu_dish_option_df_temp.loc[len(menu_dish_option_df_temp.index)] = [\n",
    "\t\t\t\t\t\trestaurant_id,\n",
    "\t\t\t\t\t\tmenu_info['dish_type_id'],\n",
    "\t\t\t\t\t\tdish['id'],\n",
    "\t\t\t\t\t\toption['id'],\n",
    "\t\t\t\t\t\toption['option_items']['min_select'],\n",
    "\t\t\t\t\t\toption['option_items']['max_select']\n",
    "\t\t\t\t]\n",
    "\t\t\t\tfor item in option['option_items']['items']:\n",
    "\t\t\t\t\tmenu_dish_option_item_df_temp.loc[len(menu_dish_option_item_df_temp.index)] = [\n",
    "\t\t\t\t\t\t\trestaurant_id,\n",
    "\t\t\t\t\t\t\tmenu_info['dish_type_id'],\n",
    "\t\t\t\t\t\t\tdish['id'],\n",
    "\t\t\t\t\t\t\toption['id'],\n",
    "\t\t\t\t\t\t\titem['id'],\n",
    "\t\t\t\t\t\t\titem['name'],\n",
    "\t\t\t\t\t\t\titem['price']['value']\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t\t\t\t\t\n",
    "\tmenu_df = pd.concat([menu_df, menu_df_temp])\n",
    "\tmenu_dish_df = pd.concat([menu_dish_df, menu_dish_df_temp])\n",
    "\tmenu_dish_option_df = pd.concat([menu_dish_option_df, menu_dish_option_df_temp])\n",
    "\tmenu_dish_option_item_df = pd.concat([menu_dish_option_item_df, menu_dish_option_item_df_temp])\n",
    "# TEST\n",
    "data_hcm = pd.read_csv('crawled_all_shops/data_hcm.csv')\n",
    "data_hcm['RestaurantId'] = data_hcm['RestaurantId'].apply(lambda x: str(x).split('.')[0] if x == x else np.nan)\n",
    "cnt = 0\n",
    "\n",
    "for i, res_id in enumerate(data_hcm['RestaurantId']):\n",
    "\tif res_id == res_id: # check nan\n",
    "\t\tget_delivery_dish(res_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c91bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "menu_df.to_csv('crawled_menu/menu.csv', sep=',', encoding='utf-8', index = False)\n",
    "menu_dish_df.to_csv('crawled_menu/menu.dish.csv', sep=',', encoding='utf-8', index = False)\n",
    "menu_dish_option_df.to_csv('crawled_menu/menu.dish.option.csv', sep=',', encoding='utf-8', index = False)\n",
    "menu_dish_option_item_df.to_csv('crawled_menu/menu.dish.option.item.csv', sep=',', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e49b62",
   "metadata": {},
   "source": [
    "- Lấy **detail** của 1 quán ăn: xây hàm nhận vào `id_quán_ăn` và lưu thông tin chi tiết quán đó (VD: min_charge, rating_avg, min_shipping_fee,...) vào file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_df = pd.DataFrame(columns=['city_id', 'district_id', 'request_id', 'categories', 'cuisines', 'total_review', 'avg', \\\n",
    "                'service_fee', 'avg_price', 'min_order_value', 'min_charge', 'minimun_shiping_fee', 'is_foody_delivery', 'min_price', 'max_price'])\n",
    "\n",
    "def get_detail(restaurant_id):\n",
    "    detail_API = requests.get(f\"https://gappapi.deliverynow.vn/api/delivery/get_detail?request_id={restaurant_id}&id_type=1\", \n",
    "                                headers={'x-foody-api-version': '1',\n",
    "                                        'x-foody-app-type': '1004',\n",
    "                                        'x-foody-client-language': 'vi',\n",
    "                                        'x-foody-client-type': '1',\n",
    "                                        'x-foody-client-version': '1',\n",
    "                                        'X-Foody-Client-Id': 'cookies.__ondemand_sessionid'\n",
    "                                        }\n",
    "                            )\n",
    "    data = detail_API.text\n",
    "    dataJson = json.loads(data)\n",
    "    if not dataJson['reply']:\n",
    "        return\n",
    "    detail_infos = dataJson['reply']['delivery_detail']\n",
    "\n",
    "    detail_df_temp = pd.DataFrame(columns=['city_id', 'district_id', 'request_id', 'categories', 'cuisines', 'total_review', 'avg', \\\n",
    "                'service_fee', 'avg_price', 'min_order_value', 'min_charge', 'minimun_shiping_fee', 'is_foody_delivery', 'min_price', 'max_price'])\n",
    "    detail_rating_df_temp = pd.DataFrame(columns=['request_id', 'total_review', 'avg'])\n",
    "    detail_delivery_df_temp = pd.DataFrame(columns=['request_id','service_fee', 'avg_price', 'min_order_value', 'min_charge', 'minimun-shiping-fee', 'is_foody_delivery'])\n",
    "    detail_price_df_temp = pd.DataFrame(columns=['request_id', 'min', 'max'])\n",
    "    \n",
    "    detail_df_temp.loc[len(detail_df_temp.index)] = [\n",
    "        detail_infos['city_id'], detail_infos['district_id'], restaurant_id, detail_infos['categories'], \\\n",
    "        detail_infos['cuisines'], detail_infos['rating']['total_review'], detail_infos['rating']['avg'], detail_infos['delivery']['service_fee']['value'],\\\n",
    "        detail_infos['delivery']['avg_price']['value'], detail_infos['delivery']['min_order_value']['value'], detail_infos['delivery']['min_charge'], \\\n",
    "        detail_infos['delivery']['shipping_fee']['minimum_fee'], detail_infos['delivery']['is_foody_delivery'], \\\n",
    "        detail_infos['price_range']['min_price'], detail_infos['price_range']['max_price']\n",
    "    ]\n",
    "\n",
    "    detail_df = pd.concat([detail_df, detail_df_temp])\n",
    "\n",
    "for i, res_id in enumerate(data_hcm['RestaurantId']):\n",
    "    if cnt > 100:\n",
    "        break\n",
    "    if res_id == res_id: # check nan\n",
    "        cnt += 1\n",
    "        get_detail(res_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67256262",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_df = pd.DataFrame(columns=['shop_id', 'name', 'short_description', 'city_id', 'district_id', 'address', \n",
    "                                'rating_total_review', 'rating_avg', 'rating_app_link',  \n",
    "                                'service_fee', 'avg_price', 'min_order_value', 'min_charge', 'min_shipping_fee', 'min_price', 'max_price', \n",
    "                                'is_foody_delivery', 'week_days', 'start_time', 'end_time'])\n",
    "shop_phone_df = pd.DataFrame(columns=['shop_id', 'phone'])\n",
    "shop_category_df = pd.DataFrame(columns=['shop_id', 'category'])\n",
    "shop_cuisine_df = pd.DataFrame(columns=['shop_id', 'cuisine'])\n",
    "shop_promotion_df = pd.DataFrame(columns=['shop_id', 'promo_code', 'discount_amount', 'min_order_amount', 'max_discount_amount', 'apply_order','max_usage_time', 'expired'])\n",
    "\n",
    "\n",
    "def get_detail(restaurant_id):\n",
    "        delivery_dish_API = requests.get(f\"https://gappapi.deliverynow.vn/api/delivery/get_detail?request_id={restaurant_id}&id_type=1\", \n",
    "                                        headers={'x-foody-api-version': '1',\n",
    "                                                'x-foody-app-type': '1004',\n",
    "                                                'x-foody-client-language': 'vi',\n",
    "                                                'x-foody-client-type': '1',\n",
    "                                                'x-foody-client-version': '1',\n",
    "                                                'X-Foody-Client-Id': 'cookies.__ondemand_sessionid'\n",
    "                                                }\n",
    "                                        )\n",
    "        data = delivery_dish_API.text\n",
    "        dataJson = json.loads(data)\n",
    "        shop = dataJson['reply']['delivery_detail']\n",
    "\n",
    "        shop_df.loc[len(shop_df.index)] = [\n",
    "                shop['id'], shop['name'], shop['short_description'], shop['city_id'], shop['district_id'], shop['address'],\n",
    "                shop['rating']['total_review'], shop['rating']['avg'], shop['rating']['app_link'],\n",
    "                shop['delivery']['service_fee']['value'], shop['delivery']['avg_price']['value'], shop['delivery']['min_order_value']['value'],\n",
    "                shop['delivery']['min_charge'], shop['delivery']['shipping_fee']['minimum_fee'],shop['price_range']['min_price'],\n",
    "                shop['price_range']['max_price'],shop['delivery']['is_foody_delivery'],\n",
    "                len(shop['delivery']['time']['week_days']), \n",
    "                shop['delivery']['time']['week_days'][0]['start_time'], \n",
    "                shop['delivery']['time']['week_days'][0]['end_time'] \n",
    "        ]\n",
    "        \n",
    "        for phone in shop['phones']:\n",
    "                shop_phone_df.loc[len(shop_phone_df.index)] = [\n",
    "                        shop['id'],\n",
    "                        phone\n",
    "                ]\n",
    "\n",
    "        for category in shop['categories']:\n",
    "                shop_category_df.loc[len(shop_category_df.index)] = [\n",
    "                        shop['id'],\n",
    "                        category\n",
    "                ]                     \n",
    "\n",
    "        for cuisine in shop['cuisines']:\n",
    "                shop_cuisine_df.loc[len(shop_cuisine_df.index)] = [\n",
    "                        shop['id'],\n",
    "                        cuisine\n",
    "                ]    \n",
    "\n",
    "        for promotion in shop['delivery']['promotions']:\n",
    "                shop_promotion_df.loc[len(shop_promotion_df.index)] = [\n",
    "                        shop['id'], promotion['promo_code'], promotion['discount_amount'], promotion['min_order_amount'], \n",
    "                        promotion['max_discount_amount'], promotion['apply_order'], promotion['user_condition']['limit_per_user']['max_usage_time'], promotion['expired']\n",
    "                ]\n",
    "\n",
    "\n",
    "for i in qbt_df['RestaurantId']:\n",
    "    get_detail(i)\n",
    "\n",
    "\n",
    "\n",
    "shop_df.to_csv('shop.csv', sep=',', encoding='utf-8')\n",
    "shop_phone_df.to_csv('shop.phone.csv', sep=',', encoding='utf-8')\n",
    "shop_category_df.to_csv('shop.category.csv', sep=',', encoding='utf-8')\n",
    "shop_cuisine_df.to_csv('shop.cuisine.csv', sep=',', encoding='utf-8')\n",
    "shop_promotion_df.to_csv('shop.promotion.csv', sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
